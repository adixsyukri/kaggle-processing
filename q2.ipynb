{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from kaggle import Kaggle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_settings():\n",
    "    with open('config.yaml', 'r') as sf:\n",
    "        settings = yaml.load(sf.read())\n",
    "    return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset process\n",
    "DATA_URL = \"https://www.kaggle.com/crawford/weekly-sales-transactions/downloads/Sales_Transactions_Dataset_Weekly.csv\"\n",
    "SETTINGS = load_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(df, n):\n",
    "    for i in range(0, df.shape[0], n):\n",
    "        yield df[i:i + n]\n",
    "\n",
    "def cleanup(classA, arr):\n",
    "    '''Cleanup Kaggle dataset since there are additional columns'''\n",
    "    for i, x in enumerate(arr[0]):\n",
    "        if (x.find('Normalized') == 0):\n",
    "            continue\n",
    "        if (x.find('MAX') == 0):\n",
    "            continue\n",
    "        if (x.find('MIN') == 0):\n",
    "            continue\n",
    "        classA.INDEX = i\n",
    "    \n",
    "    return [x[:classA.INDEX+1] for x in arr if len(x) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login to Kaggle\n",
      "Getting dataset\n"
     ]
    }
   ],
   "source": [
    "kaggle = Kaggle(SETTINGS)\n",
    "response = kaggle.get_data(DATA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform data from text to array\n"
     ]
    }
   ],
   "source": [
    "kaggle_data = kaggle.to_array(response.content.splitlines(), quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = cleanup(kaggle, kaggle_data)\n",
    "np_transpose_data = np.transpose(np.array(processed_data)) #transpose data so that product become the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dataframme\n",
    "fullData = pd.DataFrame(data=np_transpose_data[1:, 1:].astype(np.float), index=np_transpose_data[1:,0], columns=np_transpose_data[0,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1    10.0\n",
      "P2     3.5\n",
      "P3     8.0\n",
      "P4     8.0\n",
      "P5     8.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Median for all product\n",
    "median_data = fullData.median()\n",
    "\n",
    "# Print sampling\n",
    "print(median_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1    9.634615\n",
      "P2    3.980769\n",
      "P3    8.692308\n",
      "P4    8.269231\n",
      "P5    8.461538\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Mean for all product\n",
    "mean_data = fullData.mean()\n",
    "\n",
    "# Print sampling\n",
    "print(mean_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1    3.0\n",
      "P2    0.0\n",
      "P3    3.0\n",
      "P4    2.0\n",
      "P5    3.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Min for all product\n",
    "min_data = fullData.min()\n",
    "\n",
    "# Print sampling\n",
    "print(min_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1    21.0\n",
      "P2    10.0\n",
      "P3    14.0\n",
      "P4    19.0\n",
      "P5    18.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Max for all product\n",
    "max_data = fullData.max()\n",
    "\n",
    "# Print sampling\n",
    "print(max_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('P409', 2220.0)\n"
     ]
    }
   ],
   "source": [
    "# Best product based on volume\n",
    "sum_of_product = fullData.sum()\n",
    "index_array, = np.where(sum_of_product == sum_of_product.max())\n",
    "best_product = (fullData.columns[index_array[0]], sum_of_product.max())\n",
    "print(best_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most promising product (ermerging product) quite vague\n",
    "split_weekly = chunk(fullData, 1)\n",
    "top_20_every_week = [x.sum().nlargest(20) for x in split_weekly]\n",
    "top_20_last_3_week = top_20_every_week[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         sum  count\n",
      "index              \n",
      "P262   138.0      3\n"
     ]
    }
   ],
   "source": [
    "joined_group = pd.concat(top_20_last_3_week)\n",
    "resetted = joined_group.reset_index()\n",
    "resetted['count'] = 1\n",
    "most_promising_product = resetted.groupby('index').agg({0:'sum', 'count': 'count'}).rename(columns={0:'sum'}).nlargest(1, 'count')\n",
    "print(most_promising_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Biweekly 1', P212    0.0\n",
      "P213    0.0\n",
      "P214    0.0\n",
      "P215    0.0\n",
      "P216    0.0\n",
      "dtype: float64), ('Biweekly 2', P212    0.0\n",
      "P213    0.0\n",
      "P214    0.0\n",
      "P215    0.0\n",
      "P216    0.0\n",
      "dtype: float64), ('Biweekly 3', P215    0.0\n",
      "P216    0.0\n",
      "P217    0.0\n",
      "P218    0.0\n",
      "P219    0.0\n",
      "dtype: float64)]\n"
     ]
    }
   ],
   "source": [
    "# 5 worst performing product on a biweekly basis\n",
    "grouped = chunk(fullData, 2)\n",
    "sum_grouped = [i.sum() for i in grouped]\n",
    "worst_5_product_biweekly = [('Biweekly {}'.format(i+1), x.nsmallest(5)) for i, x in enumerate(sum_grouped)]\n",
    "\n",
    "# Print sampling\n",
    "print(worst_5_product_biweekly[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       P1  P2  P3    P4  P5  P6  P7  P8  P9  P10  ...   P810  P811  P812  \\\n",
      "W0    NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W1    NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W2    NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W3    NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W4    NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W5    NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W6    NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W7   21.0 NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W8    NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W9    NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W10   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W11   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   6.0   \n",
      "W12   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W13   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W14   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W15   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W16   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W17   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W18   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W19   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W20   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W21   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W22   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W23   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W24   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W25   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   9.0   NaN   \n",
      "W26   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W27   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W28   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    3.0   NaN   NaN   \n",
      "W29   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W30   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W31   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W32   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W33   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W34   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W35   NaN NaN NaN  19.0 NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W36   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    3.0   NaN   NaN   \n",
      "W37   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W38   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W39   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W40   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W41   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W42   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W43   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W44   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W45   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W46   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W47   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W48   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W49   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W50   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "W51   NaN NaN NaN   NaN NaN NaN NaN NaN NaN  NaN  ...    NaN   NaN   NaN   \n",
      "\n",
      "     P813  P814  P815  P816  P817  P818  P819  \n",
      "W0    NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W1    NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W2    NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W3    NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W4    NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W5    NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W6    NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W7    NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W8    NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W9    NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W10   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W11   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W12   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W13   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W14   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W15   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W16   NaN   NaN   3.0   NaN   NaN   NaN   NaN  \n",
      "W17   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W18   NaN   NaN   NaN   NaN   NaN   NaN   3.0  \n",
      "W19   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W20   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W21   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W22   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W23   8.0   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W24   NaN   NaN   NaN   NaN   NaN   2.0   NaN  \n",
      "W25   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W26   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W27   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W28   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W29   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W30   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W31   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W32   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W33   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W34   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W35   NaN   NaN   NaN   NaN   NaN   NaN   3.0  \n",
      "W36   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W37   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W38   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W39   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W40   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W41   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W42   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W43   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W44   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W45   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W46   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W47   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W48   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "W49   NaN  16.0   NaN   NaN   NaN   NaN   NaN  \n",
      "W50   NaN   NaN   NaN   NaN   4.0   2.0   NaN  \n",
      "W51   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "\n",
      "[52 rows x 811 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get outliers for every product\n",
    "outliers = fullData[~(np.abs(fullData - fullData.mean())<=(3*fullData.std()))]\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
