{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from kaggle import Kaggle\n",
    "import zipfile\n",
    "from io import BytesIO, StringIO\n",
    "import re\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import collections\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_settings():\n",
    "    with open('config.yaml', 'r') as sf:\n",
    "        settings = yaml.load(sf.read())\n",
    "    return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset process\n",
    "DATA_URL = \"https://www.kaggle.com/madhab/jobposts/downloads/data%20job%20posts.csv\"\n",
    "SETTINGS = load_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login to Kaggle\n",
      "Getting dataset\n"
     ]
    }
   ],
   "source": [
    "kaggle = Kaggle(SETTINGS)\n",
    "response = kaggle.get_data(DATA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_output = response.content\n",
    "archive = zipfile.ZipFile(BytesIO(archive_output), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unicoded = unicode(archive.read('data job posts.csv'), 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sio = StringIO(unicoded, newline=None)\n",
    "io_data = sio.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform data from text to array\n"
     ]
    }
   ],
   "source": [
    "kaggle_data = kaggle.to_array(io_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extract the following fields from the jobpost column:\n",
    "1. Job Title\n",
    "2. Position Duration\n",
    "3. Position Location\n",
    "4. Job Description\n",
    "5. Job Responsibilities\n",
    "6. Required Qualifications\n",
    "7. Remuneration\n",
    "8. Application Deadline\n",
    "9. About Company\n",
    "'''\n",
    "\n",
    "Jobpost = []\n",
    "list_extraction = ['job title', 'position duration', 'position location', \n",
    "                   'job description', 'job responsibilites', 'required qualifications',\n",
    "                   'remuneration', 'application deadline', 'about company']\n",
    "for i, item in enumerate(kaggle_data):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    jobpost = item[0].split('\\n')\n",
    "    extract_data = {}\n",
    "    for data in jobpost:\n",
    "        for name in list_extraction:\n",
    "            try:\n",
    "                splitted = name.upper().split(' ')\n",
    "                regex = splitted[1]\n",
    "                if re.search(regex, data):\n",
    "                    extract_data[name.replace(' ', '_')] = data\n",
    "            except:\n",
    "                if re.search(name.upper(), data):\n",
    "                    extract_data[name] = data\n",
    "    Jobpost.append(extract_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'position_location': 'POSITION LOCATION: Yerevan, Armenia', 'application_deadline': 'APPLICATION DEADLINE:   26 January 2004', 'required_qualifications': 'REQUIRED QUALIFICATIONS:  To perform this job successfully, an', 'job_description': 'JOB DESCRIPTION:   AMERIA Investment Consulting Company is seeking a', 'job_title': 'JOB TITLE:  Chief Financial Officer'}, {'required_qualifications': 'REQUIRED QUALIFICATIONS:  ', 'position_duration': 'DURATION:  3 months', 'remuneration': 'REMUNERATION:  Commensurate with experience.', 'application_deadline': 'APPLICATION DEADLINE:   12 January 2004', 'position_location': 'LOCATION:  IREX Armenia Main Office; Yerevan, Armenia ', 'job_description': 'DESCRIPTION:   IREX currently seeks to fill the position of a paid', 'about_company': 'ABOUT COMPANY:   The International Research & Exchanges Board (IREX) is', 'job_title': 'TITLE:   Full-time Community Connections Intern (paid internship)'}, {'required_qualifications': 'REQUIRED QUALIFICATIONS:  ', 'position_duration': 'POSITION DURATION:   Renewable annual contract', 'remuneration': 'REMUNERATION:  Salary commensurate with experience. ', 'application_deadline': 'APPLICATION DEADLINE:   20 January 2004', 'position_location': 'POSITION LOCATION: Yerevan, Armenia', 'job_description': 'JOB DESCRIPTION:   Public outreach and strengthening of a growing', 'about_company': 'ABOUT COMPANY:  The Caucasus Environmental NGO Network is a', 'job_title': 'JOB TITLE:  Country Coordinator'}, {'position_location': 'POSITION LOCATION: Manila, Philippines', 'application_deadline': 'APPLICATION DEADLINE:   23 January 2004', 'required_qualifications': 'REQUIRED QUALIFICATIONS:  ', 'job_description': 'JOB DESCRIPTION:  The LEAD (Local Enhancement and Development for', 'job_title': 'JOB TITLE:  BCC Specialist'}, {'position_location': 'POSITION LOCATION: Yerevan, Armenia', 'application_deadline': 'APPLICATION DEADLINE:  20 January 2004, 18:00', 'remuneration': 'REMUNERATION:  Will be commensurate with the norms accepted in the', 'required_qualifications': 'REQUIRED QUALIFICATIONS:  ', 'job_title': 'JOB TITLE:  Software Developer'}]\n"
     ]
    }
   ],
   "source": [
    "# Extracted data from jobpost for 5 sample\n",
    "print(Jobpost[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AMERIA Investment Consulting Company', '2004'), ('International Research & Exchanges Board (IREX)', '2004'), ('Caucasus Environmental NGO Network (CENN)', '2004'), ('Manoff Group', '2004'), ('Yerevan Brandy Company', '2004')]\n",
      "Maximum year: 2015\n"
     ]
    }
   ],
   "source": [
    "index_year = kaggle_data[0].index('Year')\n",
    "max_year = max([item[index_year] for i, item in enumerate(kaggle_data) if i > 0])\n",
    "company_year = [(x[0].split('\\n')[0], x[index_year]) for i, x in enumerate(kaggle_data) if i > 0]\n",
    "\n",
    "# 5 Sample of company and year\n",
    "print(company_year[:5])\n",
    "\n",
    "# Maximum year recorded in the post\n",
    "print('Maximum year: {}'.format(max_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = collections.defaultdict(list)\n",
    "for company, year in company_year:\n",
    "    if ((int(max_year) - int(year)) <= 2):\n",
    "        grouped[company].append(1)\n",
    "        \n",
    "analyzed = [(company, sum(count)) for company, count in grouped.iteritems()]\n",
    "company_most_ads = max(analyzed, key=lambda item:item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ArmenTel CJSC', 127)\n"
     ]
    }
   ],
   "source": [
    "# most company with ads in the last 2 years\n",
    "print(company_most_ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_month = kaggle_data[0].index('Month')\n",
    "grouped_month = collections.defaultdict(list)\n",
    "all_month = [item[index_month] for i, item in enumerate(kaggle_data) if i > 0]\n",
    "for month in all_month:\n",
    "    grouped_month[month].append(1)\n",
    "\n",
    "analyzed_month = [(month, sum(count)) for month, count in grouped_month.iteritems()]\n",
    "month_most_ads = max(analyzed_month, key=lambda item:item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('3', 1702)\n"
     ]
    }
   ],
   "source": [
    "# Month with largest number of job ads\n",
    "print(month_most_ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Columns Available: ', ['jobpost', 'date', 'Title', 'Company', 'AnnouncementCode', 'Term', 'Eligibility', 'Audience', 'StartDate', 'Duration', 'Location', 'JobDescription', 'JobRequirment', 'RequiredQual', 'Salary', 'ApplicationP', 'OpeningDate', 'Deadline', 'Notes', 'AboutC', 'Attach', 'Year', 'Month', 'IT'])\n"
     ]
    }
   ],
   "source": [
    "# index_job_responsibilities = kaggle_data[0].index('Job responsibilites')\n",
    "# No job responsibilities column\n",
    "print('Columns Available: ',kaggle_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_duration = kaggle_data[0].index('Duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_na(text_data, message):\n",
    "    try:\n",
    "        if re.match('NA', text_data):\n",
    "            return message\n",
    "        else:\n",
    "            return text_data\n",
    "    except:\n",
    "        if text_data is None:\n",
    "            return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Custom message', '3 months', 'Renewable annual contract\\nPOSITION', 'Custom message', 'Custom message']\n"
     ]
    }
   ],
   "source": [
    "copied = deepcopy(kaggle_data)\n",
    "for i, data in enumerate(copied):\n",
    "    if i > 0:\n",
    "        data[index_duration] = replace_na(data[index_duration], 'Custom message')\n",
    "\n",
    "# Print sample custom message in action\n",
    "print([x[index_duration] for i, x in enumerate(copied) if i > 0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(arr, n):\n",
    "    for i in range(0, len(arr), n):\n",
    "        yield arr[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_copied = list(chunk(copied, 20))[0]\n",
    "np_data = np.array(chunk_copied)\n",
    "df = pd.DataFrame(data=np_data[1:, 1:], index=np_data[1:,1], columns=np_data[0,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from s3 import S3\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client(\n",
    "            's3',\n",
    "            aws_access_key_id=SETTINGS['aws']['access'],\n",
    "            aws_secret_access_key=SETTINGS['aws']['secret']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data into s3\n",
    "obj = s3.put_object(\n",
    "            Key='q3-dataset',\n",
    "            Bucket='kaggle-df-dataset',\n",
    "            Body=df.to_csv(None)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
